# MRO AgenticOps - Quick Start Guide

## ğŸš€ InÃ­cio RÃ¡pido (5 minutos)

### 1. Verificar Status
```bash
python setup.py --check
```

### 2. Instalar DependÃªncias
```bash
# OpÃ§Ã£o 1: Com setup.py
python setup.py --setup

# OpÃ§Ã£o 2: Direto com pip
pip install -r requirements.txt
```

### 3. Iniciar Ollama (em terminal separado)
```bash
ollama serve
```

### 4. Baixar Modelo LLM
```bash
ollama pull llama3
```

### 5. Processar PDFs e Criar Ãndice
```bash
python setup.py --pipeline
```

### 6. Fazer Perguntas
```bash
python setup.py --query
```

---

## ğŸ“– Uso Detalhado

### Modo Interativo
```bash
python setup.py --query
```
Digite suas perguntas e pressione Enter. Digite `exit` para sair.

### Uso ProgramÃ¡tico
```python
from src.query import RAGPipeline

rag = RAGPipeline()
result = rag.query("O que Ã© o Modelo de Responsabilidade Organizacional?")

print(result['answer'])
```

### Executar Testes
```bash
# Todos os testes
pytest

# Apenas testes unitÃ¡rios (sem integraÃ§Ã£o)
pytest -m "not integration"

# Testes especÃ­ficos
pytest tests/test_preprocess.py
```

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar ParÃ¢metros de Retrieval
Edite `configs/default.yaml`:
```yaml
retriever:
  top_k: 10              # Mais contexto
  similarity_threshold: 0.6  # Menos restritivo
```

### Mudar Modelo LLM
```yaml
ollama:
  model: mistral  # ou mixtral, codellama, etc
```

### Ajustar Chunking
```yaml
chunking:
  chunk_size: 1024  # Chunks maiores
  chunk_overlap: 100
```

---

## ğŸ“Š Pipelines

### Pipeline de IngestÃ£o
```bash
python pipelines/ingest_pipeline.py
```
Executa: Preprocess â†’ Train (embeddings + FAISS)

### Pipeline de AvaliaÃ§Ã£o
```bash
python pipelines/eval_pipeline.py
```
Executa mÃ©tricas de qualidade do RAG

---

## ğŸ§ª Desenvolvimento

### Adicionar Novo PDF
1. Coloque o PDF em `data/raw/`
2. Execute: `python setup.py --pipeline`

### Reindexar Tudo
```bash
# Apagar Ã­ndice antigo
rm -rf data/interim/* data/processed/*

# Reprocessar
python setup.py --pipeline
```

### Debugging
```python
# Ativar logs detalhados
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ğŸ› Troubleshooting

### Erro: "Ollama server not running"
**SoluÃ§Ã£o**: Inicie o servidor
```bash
ollama serve
```

### Erro: "FAISS index not found"
**SoluÃ§Ã£o**: Execute o pipeline
```bash
python setup.py --pipeline
```

### Erro: "No PDF files found"
**SoluÃ§Ã£o**: Adicione PDFs em `data/raw/`

### Erro: ModuleNotFoundError
**SoluÃ§Ã£o**: Instale dependÃªncias
```bash
python setup.py --setup
```

---

## ğŸ“š Exemplos de Perguntas

- "O que Ã© o Modelo de Responsabilidade Organizacional?"
- "Quais sÃ£o os pilares fundamentais do MRO?"
- "Como o MRO se relaciona com governanÃ§a corporativa?"
- "Explique o conceito de accountability no contexto do MRO"

---

## ğŸ”„ Workflow Completo

```
1. PDFs â†’ data/raw/
2. python setup.py --pipeline
   â”œâ”€ preprocess.py â†’ chunks em data/interim/
   â””â”€ train.py â†’ embeddings + FAISS em data/processed/
3. python setup.py --query
   â””â”€ RAGPipeline â†’ Ollama â†’ Resposta
```

---

## ğŸ“ Suporte

- DocumentaÃ§Ã£o completa: [README.md](README.md)
- Arquitetura: Ver diagrama no README
- Issues: Criar issue no repositÃ³rio
